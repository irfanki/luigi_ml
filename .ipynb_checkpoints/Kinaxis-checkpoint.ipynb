{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/irfan/.local/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/irfan/.local/lib/python3.8/site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy in /home/irfan/.local/lib/python3.8/site-packages (1.19.1)\n",
      "Requirement already satisfied: scikit-learn in /home/irfan/.local/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/irfan/.local/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/irfan/.local/lib/python3.8/site-packages (from scipy) (1.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_tweets.csv  finalized_model.sav  main.py      README.md\t\trun.sh\r\n",
      "cities.csv\t    Kinaxis.ipynb\t pipeline.py  requirements.txt\tvenv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline = pd.read_csv(\"airline_tweets.csv\", engine='python')\n",
    "df_cities = pd.read_csv(\"cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153    False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156    False   finalized                   3     2/25/15 10:01   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                        0.0  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
       "       '_last_judgment_at', 'airline_sentiment',\n",
       "       'airline_sentiment:confidence', 'negativereason',\n",
       "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
       "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
       "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline.drop(columns=['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
    "       '_last_judgment_at',\n",
    "       'airline_sentiment:confidence', 'negativereason',\n",
    "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
    "       'name', 'negativereason_gold', 'retweet_count', 'text',\n",
    "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CleanDataTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the airline dataframe\n",
    "\n",
    "# Removing rows cantaining NAN\n",
    "df_airline.dropna(inplace=True)\n",
    "# df_airline.reset_index(drop=True, inplace= True)\n",
    "\n",
    "# Removing rows containing '0.0, 0.0'\n",
    "df_airline['tweet_coord'] = df_airline['tweet_coord'].astype(str)\n",
    "df_airline.drop(df_airline[df_airline.tweet_coord == '[0.0, 0.0]'].index, inplace=True)\n",
    "df_airline.reset_index(drop=True, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>tweet_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>negative</td>\n",
       "      <td>[40.64656067, -73.78334045]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>573</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_sentiment                  tweet_coord\n",
       "count                855                          855\n",
       "unique                 3                          831\n",
       "top             negative  [40.64656067, -73.78334045]\n",
       "freq                 573                            6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment    object\n",
       "tweet_coord          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_airline = pd.concat([df_airline,pd.get_dummies(df_airline['nearest_city'], prefix='nearest_city',drop_first=True)],axis=1)\n",
    "\n",
    "# # now drop the original 'country' column (you don't need it anymore)\n",
    "# df_airline.drop(['nearest_city'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TrainingDataTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list as string to list\n",
    "import ast\n",
    "df_airline['tweet_coord'] = df_airline['tweet_coord'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.drop(columns=['geonameid', 'asciiname', 'alternatenames',\n",
    "                        'feature class', 'feature code', 'country code', 'cc2',\n",
    "                        'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code',\n",
    "                        'population', 'elevation', 'dem', 'timezone', 'modification date'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'latitude', 'longitude'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the latitude and longitude columns of the dataframe\n",
    "df_cities['latlong'] = df_cities.apply(lambda x: list([x['latitude'],\n",
    "                                        x['longitude']]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest city logic\n",
    "from scipy.spatial import KDTree\n",
    "import numpy as np\n",
    "s1 = np.array(list(df_cities['latlong']))\n",
    "s2 = np.array(list(df_airline['tweet_coord']))\n",
    "\n",
    "kdtree = KDTree(s1)\n",
    "neighbours = kdtree.query(s2)\n",
    "\n",
    "nearest_city = []\n",
    "for i in range(len(neighbours[1])):\n",
    "    nearest_city.append(df_cities['name'][i])\n",
    "    \n",
    "df_airline['nearest_city'] = nearest_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(neighbours[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighbours[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(nearest_city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23278, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'tweet_coord', 'nearest_city'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_airline['nearest_city']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'tweet_coord', 'nearest_city'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment\n",
      "negative    573\n",
      "neutral     132\n",
      "positive    150\n",
      "dtype: int64\n",
      "airline_sentiment\n",
      "negative    126\n",
      "neutral     132\n",
      "positive    128\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_airline.groupby(['airline_sentiment']).size())\n",
    "df_airline = df_airline.drop(df_airline[df_airline['airline_sentiment'] == 'negative'].sample(frac=.78).index)\n",
    "df_airline = df_airline.drop(df_airline[df_airline['airline_sentiment'] == 'positive'].sample(frac=.15).index)\n",
    "print(df_airline.groupby(['airline_sentiment']).size())\n",
    "df_airline.reset_index(drop=True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the full screen\n",
    "pd.options.display.max_rows = 10000 \n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df_airline['airline_sentiment'])\n",
    "\n",
    "\n",
    "# print(list(le.inverse_transform([2, 2, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding \n",
    "\n",
    "X = pd.get_dummies(df_airline[\"nearest_city\"],prefix='nearest_city',drop_first=True)\n",
    "\n",
    "df = pd.concat([df_airline,pd.get_dummies(df_airline['nearest_city'], prefix='nearest_city',drop_first=True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'tweet_coord', 'nearest_city',\n",
       "       'nearest_city_Abu Dhabi', 'nearest_city_Adelaide Hills',\n",
       "       'nearest_city_Adh Dhayd', 'nearest_city_Agdzhabedy',\n",
       "       'nearest_city_Aguilares', 'nearest_city_Ajman', 'nearest_city_Al Ain',\n",
       "       ...\n",
       "       'nearest_city_Yerba Buena', 'nearest_city_Yevlakh',\n",
       "       'nearest_city_Zapala', 'nearest_city_Zaranj', 'nearest_city_Zemst',\n",
       "       'nearest_city_Zenica', 'nearest_city_Zonhoven', 'nearest_city_Zottegem',\n",
       "       'nearest_city_ZÃ¡rate', 'nearest_city_les Escaldes'],\n",
       "      dtype='object', length=388)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['airline_sentiment', 'tweet_coord', 'nearest_city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X,y)\n",
    "\n",
    "#Predict Output\n",
    "# predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "# print \"Predicted Value:\", predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 2, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956709956709957"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of training a final classification model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_blobs\n",
    "# generate 2d classification dataset\n",
    "# X, y = make_blobs(n_samples=100,random_state=1)\n",
    "# fit final model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23123812, 0.52189667, 0.24686521],\n",
       "       [0.49339273, 0.25566729, 0.25093999],\n",
       "       [0.49339273, 0.25566729, 0.25093999],\n",
       "       ...,\n",
       "       [0.49339273, 0.25566729, 0.25093999],\n",
       "       [0.49339273, 0.25566729, 0.25093999],\n",
       "       [0.49339273, 0.25566729, 0.25093999]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(list(le.inverse_transform(model.predict(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974025974025974"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "regr = svm.SVR()\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02630121, 0.57930052, 0.39439827],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 2, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02630121, 0.57930052, 0.39439827],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.09576695, 0.51172454, 0.39250851],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02326818, 0.70469284, 0.27203899],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ],\n",
       "       [0.02527541, 0.38748869, 0.5872359 ]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(df_cities[\"name\"],prefix='name',drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 22161 features per sample; expecting 230",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-decd67bbf386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 22161 features per sample; expecting 230"
     ]
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability for each prediction\n",
    "import numpy as np\n",
    "index_array = np.argmax(model.predict_proba(X_test),  axis=-1)\n",
    "prediction_probability = np.take_along_axis(model.predict_proba(X_test), np.expand_dims(index_array, axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test set\n",
    "prediction = list(le.inverse_transform(model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = list(X_test.idxmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba=[ i[0] for i in prediction_probability.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'city': city, 'prediction': prediction, 'prediction_proba': prediction_proba}\n",
    "df_test = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['prediction'] == 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nearest_city_City of Parramatta</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nearest_city_Maymana</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nearest_city_Cessnock</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nearest_city_Willetton</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nearest_city_Liverpool</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nearest_city_Meise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nearest_city_AÄdaÅ</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nearest_city_Nerang</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nearest_city_Gardez</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nearest_city_Epping</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nearest_city_Prospect</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nearest_city_Gosnells</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nearest_city_Southport</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>nearest_city_MuktÄgÄcha</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>nearest_city_Hampton Park</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>nearest_city_General Pico</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>nearest_city_Thornbury</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>nearest_city_Toowoomba</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>nearest_city_Doncaster</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>nearest_city_Lommel</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nearest_city_Newcastle</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>nearest_city_Arroyito</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>nearest_city_Saint-Nicolas</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>nearest_city_Markaz-e WoluswalÄ«-ye ÄchÄ«n</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>nearest_city_Rockhampton</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>nearest_city_Spitak</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>nearest_city_Al Ain</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>nearest_city_Sydney</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>nearest_city_Narsingdi</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>nearest_city_Kushtia</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.587236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        city prediction  prediction_proba\n",
       "3            nearest_city_City of Parramatta   positive          0.587236\n",
       "4                       nearest_city_Maymana   positive          0.587236\n",
       "8                      nearest_city_Cessnock   positive          0.587236\n",
       "14                    nearest_city_Willetton   positive          0.587236\n",
       "15                    nearest_city_Liverpool   positive          0.587236\n",
       "18                        nearest_city_Meise   positive          0.587236\n",
       "19                        nearest_city_AÄdaÅ   positive          0.587236\n",
       "24                       nearest_city_Nerang   positive          0.587236\n",
       "25                       nearest_city_Gardez   positive          0.587236\n",
       "26                       nearest_city_Epping   positive          0.587236\n",
       "27                     nearest_city_Prospect   positive          0.587236\n",
       "28                     nearest_city_Gosnells   positive          0.587236\n",
       "32                    nearest_city_Southport   positive          0.587236\n",
       "41                   nearest_city_MuktÄgÄcha   positive          0.587236\n",
       "42                 nearest_city_Hampton Park   positive          0.587236\n",
       "43                 nearest_city_General Pico   positive          0.587236\n",
       "44                    nearest_city_Thornbury   positive          0.587236\n",
       "45                    nearest_city_Toowoomba   positive          0.587236\n",
       "46                    nearest_city_Doncaster   positive          0.587236\n",
       "48                       nearest_city_Lommel   positive          0.587236\n",
       "52                    nearest_city_Newcastle   positive          0.587236\n",
       "54                     nearest_city_Arroyito   positive          0.587236\n",
       "56                nearest_city_Saint-Nicolas   positive          0.587236\n",
       "59  nearest_city_Markaz-e WoluswalÄ«-ye ÄchÄ«n   positive          0.587236\n",
       "64                  nearest_city_Rockhampton   positive          0.587236\n",
       "65                       nearest_city_Spitak   positive          0.587236\n",
       "69                       nearest_city_Al Ain   positive          0.587236\n",
       "71                       nearest_city_Sydney   positive          0.587236\n",
       "73                    nearest_city_Narsingdi   positive          0.587236\n",
       "76                      nearest_city_Kushtia   positive          0.587236"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.to_csv('City_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrainingDataTask(luigi.Task):\n",
    "#     \"\"\" Extracts features/outcome variable in preparation for training a model.\n",
    "#\n",
    "#         Output file should have columns corresponding to the training data:\n",
    "#         - y = airline_sentiment (coded as 0=negative, 1=neutral, 2=positive)\n",
    "#         - X = a one-hot coded column for each city in \"cities.csv\"\n",
    "#     \"\"\"\n",
    "#     tweet_file = luigi.Parameter()\n",
    "#     cities_file = luigi.Parameter(default='cities.csv')\n",
    "#     output_file = luigi.Parameter(default='features.csv')\n",
    "#\n",
    "#     # TODO...\n",
    "#     def requires(self):\n",
    "#         return CleanDataTask()\n",
    "#\n",
    "#     def run(self):\n",
    "#         df_clean = pd.read_csv(CleanDataTask().output().path)\n",
    "#         # Converting list as string to list\n",
    "#\n",
    "#         df_cities = pd.read_csv(self.cities_file)\n",
    "#         # combining the latitude and longitude columns of the dataframe\n",
    "#         df_cities['latlong'] = df_cities.apply(lambda x: list([x['latitude'], x['longitude']]), axis=1)\n",
    "#\n",
    "#         # Using the KDtree to locate the nearest city for the respective coordinate\n",
    "#         kdtree = scipy.spatial.KDTree(np.array(list(df_cities['latlong'])))\n",
    "#         neighbours = kdtree.query(np.array(list(df_clean['tweet_coord'])), k=1)\n",
    "#         nearest_city = []\n",
    "#         for i in range(len(neighbours[1])):\n",
    "#             nearest_city.append(df_cities['name'][i])\n",
    "#         df_clean['nearest_city'] = nearest_city\n",
    "#\n",
    "#         df_clean.drop(columns=['tweet_coord'], inplace=True)\n",
    "#\n",
    "#         with self.output().open('w') as f:\n",
    "#             # crate the final output\n",
    "#             df_clean.to_csv(f)\n",
    "#\n",
    "#     def output(self):\n",
    "#         return luigi.LocalTarget(self.output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closest city sentiment \n",
    "# Nearest city logic\n",
    "import scipy\n",
    "import numpy as np\n",
    "s2 = np.array(list(df_cities['latlong']))\n",
    "s1 = np.array(list(df_airline['tweet_coord']))\n",
    "\n",
    "kdtree = KDTree(s1)\n",
    "neighbours = kdtree.query(s2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23278\n",
      "23278\n"
     ]
    }
   ],
   "source": [
    "print(len(neighbours[1]))\n",
    "print(len(df_cities['latlong']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'tweet_coord', 'nearest_city'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23278"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_sentiment = []\n",
    "for i in neighbours[1]:\n",
    "    airline_sentiment.append(df_airline['airline_sentiment'][i])\n",
    "    \n",
    "len(airline_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9.60897953,  9.6137212 ,  0.64093232, ..., 53.56030454,\n",
       "        49.21173181, 49.35397463]),\n",
       " array([ 34,  34,  98, ..., 100, 100, 100]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities['airline_sentiment'] = airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'latitude', 'longitude', 'latlong', 'airline_sentiment'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.drop(columns = ['latitude', 'longitude', 'latlong'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment\n",
      "negative     1575\n",
      "neutral     14722\n",
      "positive     6981\n",
      "dtype: int64\n",
      "airline_sentiment\n",
      "negative     725\n",
      "neutral     7361\n",
      "positive    6981\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cities.groupby(['airline_sentiment']).size())\n",
    "df_cities = df_cities.drop(df_cities[df_cities['airline_sentiment'] == 'negative'].sample(frac=.54).index)\n",
    "df_cities = df_cities.drop(df_cities[df_cities['airline_sentiment'] == 'neutral'].sample(frac=.50).index)\n",
    "print(df_cities.groupby(['airline_sentiment']).size())\n",
    "df_cities.reset_index(drop=True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15067\n",
      "15067\n"
     ]
    }
   ],
   "source": [
    "print(len(df_cities['name']))\n",
    "print(len(df_cities['airline_sentiment']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'airline_sentiment'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the full screen\n",
    "pd.options.display.max_rows = 10000 \n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df_cities['airline_sentiment'])\n",
    "\n",
    "# One hot encoding \n",
    "\n",
    "X = pd.get_dummies(df_cities[\"name\"],prefix='name',drop_first=True)\n",
    "\n",
    "# df = pd.concat([df_cities,pd.get_dummies(df_cities['name'], prefix='name',drop_first=True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_cities,pd.get_dummies(df_cities['name'], prefix='name',drop_first=True)],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities_01 = df_cities\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df_cities['airline_sentiment'])\n",
    "X = pd.get_dummies(df_cities[\"name\"],prefix='name',drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_cities\n",
    "\n",
    "df_feature['airline_sentiment'] = le.fit_transform(df_cities['airline_sentiment'])\n",
    "df_feature = pd.concat([df_cities,pd.get_dummies(df_cities['name'], prefix='name',drop_first=True)],axis=1)\n",
    "df_feature.drop(columns=['name'], inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'name_A CoruÃ±a', 'name_Aabenraa', 'name_Aachen',\n",
       "       'name_Aalborg', 'name_Aalen', 'name_Aalten', 'name_Aalter',\n",
       "       'name_Aarau', 'name_Abadan',\n",
       "       ...\n",
       "       'name_âAqrah', 'name_âArad', 'name_âAyn al âArab', 'name_âAÃ¯n Abid',\n",
       "       'name_âAÃ¯n Deheb', 'name_âAÃ¯n Merane', 'name_âAÃ¯n el Bell',\n",
       "       'name_âAÃ¯n el Berd', 'name_âAÃ¯n el Melh', 'name_âAÃ¯n el Turk'],\n",
       "      dtype='object', length=14565)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_feature.pop('airline_sentiment')\n",
    "X = df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVR()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the pandas dummy\n",
    "name = X.idxmax(axis=1)\n",
    "city_name = list(map( lambda x: x.replace( 'name_', ''), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_probability = loaded_model.predict_proba(X)[:,0]\n",
    "neutral_probability =loaded_model.predict_proba(X)[:,1]\n",
    "positive_probability =loaded_model.predict_proba(X)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(city_name, negative_probability, neutral_probability, positive_probability)), \n",
    "                  columns =['city_name', 'negative_probability', 'neutral_probability', 'positive_probability']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=1)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities['negative_probability'] = model.predict_proba(X)[:,0]\n",
    "df_cities['neutral_probability'] = model.predict_proba(X)[:,1]\n",
    "df_cities['positive_probability'] = model.predict_proba(X)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.drop(columns =['airline_sentiment'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.sort_values('positive_probability', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.to_csv('score.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 12425 features per sample; expecting 230",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-306-d2834a33d0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m             \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 \u001b[0;31m# Workaround for multi_class=\"multinomial\" and binary outcomes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 12425 features per sample; expecting 230"
     ]
    }
   ],
   "source": [
    "print(len(model.predict_proba(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.inverse_transform(model.predict(X)))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 --> Negetive\n",
    "1 --> Neutral\n",
    "2 --> Positive\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
