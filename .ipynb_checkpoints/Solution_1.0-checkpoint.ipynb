{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/irfan/.local/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/irfan/.local/lib/python3.8/site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy in /home/irfan/.local/lib/python3.8/site-packages (1.19.1)\n",
      "Requirement already satisfied: scikit-learn in /home/irfan/.local/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/irfan/.local/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy in /home/irfan/.local/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/irfan/.local/lib/python3.8/site-packages (from scipy) (1.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install numpy\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline = pd.read_csv(\"airline_tweets.csv\", engine='python')\n",
    "df_cities = pd.read_csv(\"cities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CleanDataTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the airline dataframe\n",
    "\n",
    "# Removing rows cantaining NAN\n",
    "df_airline.dropna(subset=['tweet_coord'], inplace=True)\n",
    "# df_airline.reset_index(drop=True, inplace= True)\n",
    "\n",
    "# Removing rows containing '0.0, 0.0'\n",
    "df_airline['tweet_coord'] = df_airline['tweet_coord'].astype(str)\n",
    "df_airline.drop(df_airline[df_airline.tweet_coord == '[0.0, 0.0]'].index, inplace=True)\n",
    "df_airline.reset_index(drop=True, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TrainingDataTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list as string to list\n",
    "df_airline['tweet_coord'] = df_airline['tweet_coord'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Dropping the dublicate values for the cities\n",
    "df_cities = df_cities.drop_duplicates(subset='name', keep=\"first\")\n",
    "df_cities.reset_index(drop=True, inplace= True)\n",
    "\n",
    "# combining the latitude and longitude columns of the dataframe\n",
    "df_cities['latlong'] = df_cities.apply(lambda x: list([x['latitude'],x['longitude']]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest city logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closest city sentiment \n",
    "s2 = np.array(list(df_cities['latlong']))\n",
    "s1 = np.array(list(df_airline['tweet_coord']))\n",
    "\n",
    "kdtree = KDTree(s1)\n",
    "neighbours = kdtree.query(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_sentiment = []\n",
    "for i in neighbours[1]:\n",
    "    airline_sentiment.append(df_airline['airline_sentiment'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(list(zip(df_cities['name'], airline_sentiment)),\n",
    "                           columns=['city_name', 'airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment\n",
      "negative    9481\n",
      "neutral     8534\n",
      "positive    4147\n",
      "dtype: int64\n",
      "airline_sentiment\n",
      "negative    4361\n",
      "neutral     4267\n",
      "positive    4147\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_features.groupby(['airline_sentiment']).size())\n",
    "df_features = df_features.drop(df_features[df_features['airline_sentiment'] == 'negative'].sample(frac=.54).index)\n",
    "df_features = df_features.drop(df_features[df_features['airline_sentiment'] == 'neutral'].sample(frac=.50).index)\n",
    "print(df_features.groupby(['airline_sentiment']).size())\n",
    "df_features.reset_index(drop=True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df_features['airline_sentiment'] = le.fit_transform(df_features['airline_sentiment'])\n",
    "df_features = pd.concat([df_features, pd.get_dummies(df_features['city_name'], prefix='city_name', drop_first=True)], axis=1)\n",
    "df_features.drop(columns=['city_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TrainingModelTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_features.pop('airline_sentiment')\n",
    "X = df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ScoreTask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the pandas dummy\n",
    "name = X.idxmax(axis=1)\n",
    "city_name = list(map( lambda x: x.replace( 'city_name_', ''), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_probability = loaded_model.predict_proba(X)[:,0]\n",
    "neutral_probability =loaded_model.predict_proba(X)[:,1]\n",
    "positive_probability =loaded_model.predict_proba(X)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(city_name, negative_probability, neutral_probability, positive_probability)), \n",
    "                  columns =['city_name', 'negative_probability', 'neutral_probability', 'positive_probability']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('positive_probability', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>negative_probability</th>\n",
       "      <th>neutral_probability</th>\n",
       "      <th>positive_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>Skopin</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079</th>\n",
       "      <td>Murrysville</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>Leichlingen</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>Jalingo</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>Lebach</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Remedios</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>Regla</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>Ranchuelo</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>Placetas</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>Pinar del Río</td>\n",
       "      <td>0.250874</td>\n",
       "      <td>0.246325</td>\n",
       "      <td>0.502801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city_name  negative_probability  neutral_probability  \\\n",
       "9353          Skopin              0.250874             0.246325   \n",
       "12079    Murrysville              0.250874             0.246325   \n",
       "2915     Leichlingen              0.250874             0.246325   \n",
       "7916         Jalingo              0.250874             0.246325   \n",
       "2918          Lebach              0.250874             0.246325   \n",
       "...              ...                   ...                  ...   \n",
       "2520        Remedios              0.250874             0.246325   \n",
       "2521           Regla              0.250874             0.246325   \n",
       "2522       Ranchuelo              0.250874             0.246325   \n",
       "2524        Placetas              0.250874             0.246325   \n",
       "2525   Pinar del Río              0.250874             0.246325   \n",
       "\n",
       "       positive_probability  \n",
       "9353               0.502801  \n",
       "12079              0.502801  \n",
       "2915               0.502801  \n",
       "7916               0.502801  \n",
       "2918               0.502801  \n",
       "...                     ...  \n",
       "2520               0.502801  \n",
       "2521               0.502801  \n",
       "2522               0.502801  \n",
       "2524               0.502801  \n",
       "2525               0.502801  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
